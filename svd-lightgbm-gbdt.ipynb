{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(param, X, y, X_test=None):\n",
    "    print(param)\n",
    "    if X_test is not None:\n",
    "        n_splits = 10\n",
    "        n_estimators = 1000000\n",
    "        predictions = np.zeros(len(X_test))\n",
    "        decom = TruncatedSVD(n_components=param['n_components'], random_state=7485)\n",
    "    else:\n",
    "        n_splits = 5\n",
    "        n_estimators = 300\n",
    "        predictions = None\n",
    "    folds = StratifiedKFold(n_splits=n_splits, random_state = 7485, shuffle=True)\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    pca_pipeline = Pipeline([\n",
    "        ('decomposition', TruncatedSVD(n_components=param['n_components'], random_state=7485)),\n",
    "        ('model', lgb.LGBMModel(n_estimators=n_estimators, **param))\n",
    "    ])\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        if X_test is not None:\n",
    "            decom.fit(X=X.iloc[trn_idx].values, y=y.iloc[trn_idx].values)\n",
    "            eval_set = [\n",
    "                (decom.transform(X.iloc[trn_idx]), y.iloc[trn_idx]),\n",
    "                (decom.transform(X.iloc[val_idx]), y.iloc[val_idx])\n",
    "            ]\n",
    "            clf = pca_pipeline.fit(\n",
    "                X=X.iloc[trn_idx].values, y=y.iloc[trn_idx].values, model__eval_set=eval_set, \n",
    "                model__eval_metric=param['eval_metric'], model__early_stopping_rounds = 1000, model__verbose=1000)\n",
    "            predictions += clf.predict(X_test, num_iteration=clf.named_steps['model'].best_iteration_) / folds.n_splits\n",
    "        else:\n",
    "            clf = pca_pipeline.fit(X=X.iloc[trn_idx].values, y=y.iloc[trn_idx].values)\n",
    "        oof[val_idx] = clf.predict(X.iloc[val_idx], num_iteration=clf.named_steps['model'].best_iteration_)\n",
    "\n",
    "    score = roc_auc_score(y, oof)\n",
    "    print(\"CV score: {:<8.5f}\".format(score))\n",
    "    if X_test is not None:\n",
    "        return predictions\n",
    "    else:\n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    #'n_components': 75,\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric': 'auc',\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 0,\n",
    "    #'num_leaves': 10,\n",
    "    #'min_child_samples': 80,\n",
    "    #'colsample_bytree': 0.05,\n",
    "    'subsample_freq': 5,\n",
    "    #'subsample': 0.4,\n",
    "    #'min_child_weight': 10.0,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data, num_feature = train_df.shape\n",
    "MAX_NUM_LEAVES = min(100, num_feature//10)\n",
    "MAX_MIN_DATA_IN_LEAF = 100\n",
    "print(num_data, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param['n_components'] = trial.suggest_int('n_components', 1, X.shape[1]-1)\n",
    "    param['num_leaves'] = trial.suggest_int('num_leaves', 2, MAX_NUM_LEAVES)\n",
    "    param['min_child_samples'] = trial.suggest_int('min_child_samples', 0, MAX_MIN_DATA_IN_LEAF)\n",
    "    param['min_child_weight'] = trial.suggest_loguniform('min_child_weight', 1e-5, 20)\n",
    "    param['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0.01, 1.0)\n",
    "    #param['subsample_freq'] = trial.suggest_int('subsample_freq', 0, 5)\n",
    "    #param['learning_rate'] = trial.suggest_loguniform('learning_rate', 0.001, 0.3)\n",
    "    \n",
    "    if param['subsample_freq'] > 0:\n",
    "        param['subsample'] = trial.suggest_uniform('subsample', 0.01, 1.0)\n",
    "\n",
    "    if param['boosting_type'] == 'dart':\n",
    "        param['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n",
    "        param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "    if param['boosting_type'] == 'goss':\n",
    "        param['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n",
    "        param['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - param['top_rate'])\n",
    "\n",
    "    score = cv(param, X, y)\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Different Columns from train and test\n",
    "print('\\nTrain and Test Datasets have the same columns?:',\n",
    "      train_df.drop('target',axis=1).columns.tolist()==test_df.columns.tolist())\n",
    "print(\"\\nVariables not in test but in train : \", \n",
    "      set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))\n",
    "dif = list(set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "X_test = test_df.drop(['ID_code'], axis=1)\n",
    "y = train_df.target\n",
    "print(len(X), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=200)\n",
    "#pca.fit(X.values)\n",
    "#plt.bar([n for n in range(1, len(pca.explained_variance_ratio_)+1)], pca.explained_variance_ratio_)\n",
    "#ev_ratio = pca.explained_variance_ratio_\n",
    "#ev_ratio = np.hstack([0,ev_ratio.cumsum()])\n",
    "#plt.plot(ev_ratio)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Tuning\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "best_params = study.best_params\n",
    "\n",
    "print('  Value: {}'.format(trial.value))\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model using BEST parameters, then predict test data\n",
    "print(\"svd_lgb_model ...\")\n",
    "param.update(best_params)\n",
    "param['verbosity'] = 1\n",
    "prediction = cv(param, X, y, X_test)\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "test_df['target'] = prediction\n",
    "submission_string = 'svd_gbm_' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.csv'\n",
    "test_df.loc[:, ['ID_code', 'target']].to_csv(submission_string, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
