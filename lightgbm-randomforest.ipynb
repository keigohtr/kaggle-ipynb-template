{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(param, X, y, X_test=None):\n",
    "    print(param)\n",
    "    if X_test is not None:\n",
    "        n_splits = 10\n",
    "        predictions = np.zeros(len(X_test))\n",
    "    else:\n",
    "        n_splits = 5\n",
    "        predictions = None\n",
    "    folds = StratifiedKFold(n_splits=n_splits, random_state = 7485, shuffle=True)\n",
    "    oof = np.zeros(len(X))\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X.iloc[val_idx], label=y.iloc[val_idx])\n",
    "        if X_test is not None:\n",
    "            num_round = 1000000\n",
    "            clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 1000)\n",
    "            predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "        else:\n",
    "            num_round = 300\n",
    "            clf = lgb.train(param, trn_data, num_round)\n",
    "        oof[val_idx] = clf.predict(X.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "    score = roc_auc_score(y, oof)\n",
    "    print(\"CV score: {:<8.5f}\".format(score))\n",
    "    if X_test is not None:\n",
    "        return predictions\n",
    "    else:\n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'rf',\n",
    "    'metric': 'auc',\n",
    "    'num_threads': 8,\n",
    "    'verbosity': 0,\n",
    "    #'num_leaves': 10,\n",
    "    #'min_data_in_leaf': 80,\n",
    "    #'feature_fraction': 0.05,\n",
    "    'bagging_freq': 5,\n",
    "    #'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    #'min_sum_hessian_in_leaf': 10.0,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    \"tree_learner\": \"serial\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data, num_feature = train_df.shape\n",
    "MAX_NUM_LEAVES = min(100, num_feature//10)\n",
    "MAX_MIN_DATA_IN_LEAF = 100\n",
    "print(num_data, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param['num_leaves'] = trial.suggest_int('num_leaves', 2, MAX_NUM_LEAVES)\n",
    "    param['min_data_in_leaf'] = trial.suggest_int('min_data_in_leaf', 0, MAX_MIN_DATA_IN_LEAF)\n",
    "    param['min_sum_hessian_in_leaf'] = trial.suggest_loguniform('min_sum_hessian_in_leaf', 1e-5, 20)\n",
    "    param['feature_fraction'] = trial.suggest_uniform('feature_fraction', 0.01, 1.0)\n",
    "    #param['bagging_freq'] = trial.suggest_int('bagging_freq', 0, 5)\n",
    "    #param['learning_rate'] = trial.suggest_loguniform('learning_rate', 0.001, 0.3)\n",
    "    \n",
    "    if param['bagging_freq'] > 0:\n",
    "        param['bagging_fraction'] = trial.suggest_uniform('bagging_fraction', 0.01, 1.0)\n",
    "\n",
    "    if param['boosting_type'] == 'dart':\n",
    "        param['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n",
    "        param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "    if param['boosting_type'] == 'goss':\n",
    "        param['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n",
    "        param['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - param['top_rate'])\n",
    "\n",
    "    score = cv(param, X, y)\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Different Columns from train and test\n",
    "print('\\nTrain and Test Datasets have the same columns?:',\n",
    "      train_df.drop('target',axis=1).columns.tolist()==test_df.columns.tolist())\n",
    "print(\"\\nVariables not in test but in train : \", \n",
    "      set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))\n",
    "dif = list(set(train_df.drop('target',axis=1).columns).difference(set(test_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "X_test = test_df.drop(['ID_code'], axis=1)\n",
    "y = train_df.target\n",
    "print(len(X), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Tuning\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "best_params = study.best_params\n",
    "\n",
    "print('  Value: {}'.format(trial.value))\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model using BEST parameters, then predict test data\n",
    "print(\"randomforest_model ...\")\n",
    "param.update(best_params)\n",
    "param['verbosity'] = 1\n",
    "prediction = cv(param, X, y, X_test)\n",
    "print(\"...Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "test_df['target'] = prediction\n",
    "submission_string = 'randomforest_' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.csv'\n",
    "test_df.loc[:, ['ID_code', 'target']].to_csv(submission_string, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
